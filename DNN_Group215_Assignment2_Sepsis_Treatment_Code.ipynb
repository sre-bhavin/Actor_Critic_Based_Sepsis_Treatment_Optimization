{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sre-bhavin/Actor_Critic_Based_Sepsis_Treatment_Optimization/blob/main/DNN_Group215_Assignment2_Sepsis_Treatment_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `---------------Mandatory Information to fill------------`"
      ],
      "metadata": {
        "id": "j7jO_ata_tGB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5BJ7jLz7afs"
      },
      "source": [
        "### Group ID:\n",
        "### Group Members Name with Student ID:\n",
        "1. Student 1\n",
        "2. Student 2\n",
        "3. Student 3\n",
        "4. Student 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`-------------------Write your remarks (if any) that you want should get consider at the time of evaluation---------------`"
      ],
      "metadata": {
        "id": "YXHhoNgkAhUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarks: ##Add here"
      ],
      "metadata": {
        "id": "-5tK16CbA5X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective:\n",
        "The goal of this assignment is to model the ICU treatment process using Reinforcement Learning, specifically the Actor-Critic method. The agent should learn an optimal intervention policy from historical ICU data. Each patient's ICU stay is treated as an episode consisting of time-stamped clinical observations and treatments.\n",
        "Your tasks:\n",
        "1.\tModel the ICU treatment process as a Reinforcement Learning (RL) environment.\n",
        "2.\tTrain an Actor-Critic agent to suggest medical interventions based on the patient‚Äôs current state (vitals and demographics).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "smBpMKNHawqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset:\n",
        "\n",
        "Use the dataset provided in the following link:\n",
        "\n",
        "https://drive.google.com/file/d/1UPsOhUvyrsrC59ilXsvHwGZhzm7Yk01w/view?usp=sharing\n",
        "\n",
        "**Features:**\n",
        "\n",
        "‚Ä¢\t*Vitals*: mean_bp, spo2, resp_rate\n",
        "\n",
        "‚Ä¢\t*Demographics*: age, gender\n",
        "\n",
        "‚Ä¢\t*Action*: Medical intervention (e.g., \"Vancomycin\", \"NaCl 0.9%\", or NO_ACTION)\n",
        "\n",
        "‚Ä¢\t*Identifiers*: timestamp, subject_id, hadm_id, icustay_id\n"
      ],
      "metadata": {
        "id": "JKUrRkR4bFxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State Space :\n",
        "\n",
        "Each state vector consists of: mean_bp (Mean Blood Pressure) , spo2 (Oxygen Saturation), resp_rate (Respiratory Rate), age, One-hot encoded gender\n"
      ],
      "metadata": {
        "id": "u4yLcPvCbRrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action Space :\n",
        "\n",
        "‚Ä¢\tThe agent selects one discrete action from 99 possible medical interventions (e.g., Vancomycin, Fentanyl, PO Intake, etc.\n",
        "\n",
        "‚Ä¢\tYou should integer encode or one-hot encode these interventions.\n",
        "\n"
      ],
      "metadata": {
        "id": "O3OUEjrfblhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reward Function:\n",
        "\n",
        "At each time step, the agent receives a reward based on how close the patient's vitals are to clinically normal ranges. The reward encourages the agent to take actions that stabilize the patient's vital signs:\n",
        "\n",
        "$$\n",
        "\\text{Reward}_t = - \\left( (MBP_t - 90)^2 + (SpO2_t - 98)^2 + (RR_t - 16)^2 \\right)\n",
        "$$\n",
        "\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "‚Ä¢\tMBP (mean_bp): Target = 90 mmHg\n",
        "\n",
        "‚Ä¢\tSpO‚ÇÇ (spo2): Target = 98%\n",
        "\n",
        "‚Ä¢\tRR (resp_rate): Target = 16 breaths/min\n",
        "\n",
        "Each term penalizes the squared deviation from the healthy target. The smaller the difference, the higher (less negative) the reward.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Suppose at time t, the vitals are:\n",
        "\n",
        "‚Ä¢\tMBP = 88\n",
        "\n",
        "‚Ä¢\tSpO‚ÇÇ = 97\n",
        "\n",
        "‚Ä¢\tRR = 20\n",
        "\n",
        "Then the reward is:\n",
        "\n",
        "$$\n",
        "\\text{Reward}_t = - \\left[ (88 - 90)^2 + (97 - 98)^2 + (20 - 16)^2 \\right] = - (4 + 1 + 16) = -21\n",
        "$$\n",
        "\n",
        "\n",
        "*A lower (more negative) reward indicates worse vitals, guiding the agent to learn actions that minimize this penalty.*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wfitJkYUcs0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìç Episode Termination\n",
        "\n",
        "An episode ends when the ICU stay ends. To define this:\n",
        "\n",
        "1. **Group the data** by `subject_id`, `hadm_id`, and `icustay_id`  \n",
        "   ‚Üí Each group represents one ICU stay = one episode.\n",
        "\n",
        "2. **Sort each group** by `timestamp`  \n",
        "   ‚Üí Ensures the time progression is correct.\n",
        "\n",
        "3. **For each time step** in a group (i.e., each row):  \n",
        "   ‚Üí Check if it is the **last row** in that group.  \n",
        "   &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ If **yes**, then mark `done = True` (end of episode)  \n",
        "   &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ If **no**, then mark `done = False` (continue episode)\n"
      ],
      "metadata": {
        "id": "BlI52uw0R66Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements and Deliverables:\n",
        "\n",
        "Implement the Sepsis\n",
        "Treatment Optimization Problem for the given above scenario for the below mentioned RL method."
      ],
      "metadata": {
        "id": "StV2UkLKdwMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize constants"
      ],
      "metadata": {
        "id": "ZGMBmb9OeCCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n"
      ],
      "metadata": {
        "id": "q517AMe7dyU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset    (0.5 Mark)"
      ],
      "metadata": {
        "id": "GMzlXiFBeM8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Dataset loading and preprocessing\n",
        "#-----write your code below this line---------\n",
        "\n",
        "# Convert timestamps to datetime format and sort by time within each ICU stay.\n",
        "# Encode categorical columns such as gender and action.\n",
        "\n"
      ],
      "metadata": {
        "id": "CEGbGsxWeRtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design a SepsisTreatmentEnv Environment (0.5 Mark)"
      ],
      "metadata": {
        "id": "8mfYQVh8e_6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for environment creation\n",
        "#-----write your code below this line---------\n",
        "\n",
        "class SepsisTreatmentEnv:"
      ],
      "metadata": {
        "id": "YHc3gLbpfHPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the Reward Function  (1 Mark)\n"
      ],
      "metadata": {
        "id": "3UXNXGIjf9Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for reward function\n",
        "#-----write your code below this line-------\n",
        "\n",
        "def Reward():\n",
        "  #-------"
      ],
      "metadata": {
        "id": "0ZILFSQJgBrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design and train Actor-Critic Algorithm  (2.5 Mark)\n"
      ],
      "metadata": {
        "id": "2rz6hJmThHe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for training\n",
        "#-----write your code below this line------"
      ],
      "metadata": {
        "id": "5U5Y787phKRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the graph for Average Reward   (1 Mark)"
      ],
      "metadata": {
        "id": "mvRLU6xUiHVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for plotting the average reward\n",
        "#-----write your code below this line------"
      ],
      "metadata": {
        "id": "5DJc8eH-iMCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide a 200-word writeup on the behavior, reward trends, and stability of the trained policy\t  (0.5 Mark)\n"
      ],
      "metadata": {
        "id": "tscCkZsHiSwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zM0eAlD9Bqc2"
      }
    }
  ]
}